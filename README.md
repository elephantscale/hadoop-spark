# Code repository for O'reilly course : 'Integrating Hadoop and Spark'


 ## Getting Started
You can clone this repository as follows
```
    $   git   clone   git@github.com:elephantscale/hadoop-spark.git
```


## Lab Order
1. [Dev environment setup](dev-env-setup/README.md)
2. [Hadoop setup](hadoop-setup/README.md)
3. [Spark Shell](spark-shell/README.md)
4. [Dataframes](dataframe/README.md)
